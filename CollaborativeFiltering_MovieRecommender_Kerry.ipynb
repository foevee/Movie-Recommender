{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pmype6X4bBPu"
   },
   "source": [
    "# Air Liquide Code Challenge -  Movie Recommendation\n",
    "\n",
    "## Collaborative Filtering\n",
    "\n",
    "We investigate two algorithms for collaborative filtering\n",
    "\n",
    "- Item-based neighborhood methods\n",
    "- Matrix factorization\n",
    "\n",
    "The following notebook is implemented in colab, thus there are some configurations specific to colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giLYH3FlbBPv"
   },
   "source": [
    "## 1. Preliminaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VVnEbmdbBPw"
   },
   "source": [
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T23:16:07.831454Z",
     "start_time": "2019-09-07T23:16:06.225275Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWHU3MM5bBPx",
    "outputId": "2842ebff-8cb5-410e-a11d-f0100131f975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seed=1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "5VpMzOQh9O-a"
   },
   "outputs": [],
   "source": [
    "# This configuration is required by some GPUs and not others, assuming only one gpu\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if  len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    assert tf.config.experimental.get_memory_growth(physical_devices[0]) == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nryiNWr-bBQB"
   },
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T23:19:23.937878Z",
     "start_time": "2019-09-07T23:19:23.933923Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0gLZQuQbBQB",
    "outputId": "cc805e35-cc27-4ab8-9da9-a3bd7d0f4c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-05 21:33:52--  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/zip]\n",
      "Saving to: ‘ml-latest-small.zip’\n",
      "\n",
      "ml-latest-small.zip 100%[===================>] 955.28K  3.32MB/s    in 0.3s    \n",
      "\n",
      "2020-11-05 21:33:52 (3.32 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
      "\n",
      "Archive:  ml-latest-small.zip\n",
      "   creating: ml-latest-small/\n",
      "  inflating: ml-latest-small/links.csv  \n",
      "  inflating: ml-latest-small/tags.csv  \n",
      "  inflating: ml-latest-small/ratings.csv  \n",
      "  inflating: ml-latest-small/README.txt  \n",
      "  inflating: ml-latest-small/movies.csv  \n"
     ]
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "!unzip -o ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T23:19:25.187662Z",
     "start_time": "2019-09-07T23:19:25.177975Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "qPaKzje6bBQF",
    "outputId": "7890961e-9f1b-4402-d63f-764d1038d844"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location='ml-latest-small/'\n",
    "data_ratings=pd.read_csv(location+'ratings.csv')\n",
    "data_movies=pd.read_csv(location+'movies.csv')\n",
    "data_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62kCtn0Q9eFV",
    "outputId": "fb197e7d-da53-4992-d436-5bb475e6c542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "#check the data integrity\n",
    "data_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "UUcGILIy3wsm",
    "outputId": "dc923688-67c2-4449-97e0-92307f93591b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Rating distribution')"
      ]
     },
     "execution_count": 179,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the distribution of the rating data\n",
    "data_ratings['rating'].hist()\n",
    "plt.title('Rating distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OriSEeVbBQW"
   },
   "source": [
    "### Train Test Split\n",
    "\n",
    "Here we do not handle carefuly new users or new movies (we just asign them at random)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVFi8xym9Wul",
    "outputId": "4d36fd3b-ef47-42fe-9e04-201205670df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 9724\n"
     ]
    }
   ],
   "source": [
    "#shuffle the data\n",
    "data_ratings=data_ratings.sample(frac=1)\n",
    "\n",
    "\n",
    "#encoder to continuous range\n",
    "userEncoder=LabelEncoder()\n",
    "movieEncoder=LabelEncoder()\n",
    "\n",
    "users_all=userEncoder.fit_transform(data_ratings[[\"userId\"]].values.ravel())\n",
    "movies_all=movieEncoder.fit_transform(data_ratings[[\"movieId\"]].values.ravel())\n",
    "ratings_all=data_ratings[[\"rating\"]].values.ravel()\n",
    "\n",
    "#unique users and movies\n",
    "unique_users=userEncoder.classes_\n",
    "unique_movies=movieEncoder.classes_\n",
    "\n",
    "N_users=len(unique_users)\n",
    "N_movies=len(unique_movies)\n",
    "print(N_users,N_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T23:19:55.735437Z",
     "start_time": "2019-09-07T23:19:55.548969Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUf78zSObBQa",
    "outputId": "6cba3096-814c-4d8c-91cc-63bcfe937e17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 72853, validation size 12857, test size 15126\n"
     ]
    }
   ],
   "source": [
    "users, users_test, movies, movies_test, ratings, ratings_test=train_test_split(users_all,movies_all,ratings_all,test_size=0.15) #split test set\n",
    "users_train, users_val, movies_train, movies_val, ratings_train,ratings_val=train_test_split(users,movies,ratings,test_size=0.15) #split train and validation set\n",
    "\n",
    "print(f\"train size {users_train.shape[0]}, validation size {users_val.shape[0]}, test size {users_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T23:19:56.989429Z",
     "start_time": "2019-09-07T23:19:56.856515Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7RwUl_9bBQc",
    "outputId": "c92cb4ca-6911-4e87-eea1-d8a6b8374f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "unknown_users=~np.isin(users_val, users)\n",
    "unknown_movies=~np.isin(movies_val, movies)\n",
    "print(unknown_users.sum(), unknown_movies.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wp2RDirOBr-G"
   },
   "source": [
    "## 3. Item-based Neighborhood Model\n",
    "\n",
    "For item-based neighborhood model, the target is to build an item-item matrix determining relationships between pairs of items. Here we infer the tastes of the current user by examining the matrix and matching that user's data. We use cosine similarity to measure the difference between two items (movies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViVPeuEnM_tx"
   },
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "HNIVksyl6Mcs"
   },
   "outputs": [],
   "source": [
    "class ItemBasedCF:\n",
    "    \"\"\"\n",
    "    Item-based Collaborative filtering.\n",
    "    Top-N recommendation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k_similar_movie=20, n_rec_movie=10):\n",
    "        \"\"\"\n",
    "        Init UserBasedCF with k_sim_item and n_rec_item.\n",
    "        \"\"\"\n",
    "        print(\"Start Item-based Collaborative filtering ...\\n\")\n",
    "        self.k_similar_item = k_similar_movie\n",
    "        self.n_rec_item = n_rec_movie\n",
    "        self.trainset = None\n",
    "    \n",
    "    def calculate_item_popular(self, data):\n",
    "        \"\"\"\n",
    "        Counting movies number and popularity\n",
    "        \"\"\"\n",
    "        movie_popular = defaultdict(int)\n",
    "        for user, movies in data.items():\n",
    "            for movie in movies:\n",
    "                # count item popularity\n",
    "                movie_popular[movie] += 1\n",
    "        \n",
    "        # save the total movie number, which will be used in evaluation\n",
    "        movie_count = len(movie_popular)\n",
    "        return movie_popular, movie_count\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_item_similarity(self, data):\n",
    "        \"\"\"\n",
    "        Calculate the item cosine similarity matrix using the movie-users inverse table\n",
    "        The calculating will only between items which are voted by common users\n",
    "        \"\"\"\n",
    "\n",
    "        movie_popular, movie_count = self.calculate_item_popular(data)\n",
    "\n",
    "        # count co-rated items between users\n",
    "        print('generate items co-rated similarity matrix...')\n",
    "        # set item_sim_matrix as a two-dim table: [movie_id1][co-existing_movie_is2]\n",
    "        \n",
    "        item_similar_matrix = {}\n",
    "        for user, movies in data.items():\n",
    "            for movie1, movie2 in list(itertools.combinations(movies, 2)):\n",
    "                item_similar_matrix.setdefault(movie1, defaultdict(int))\n",
    "                item_similar_matrix.setdefault(movie2, defaultdict(int))\n",
    "                item_similar_matrix[movie1][movie2] += 1\n",
    "                item_similar_matrix[movie2][movie1] += 1 \n",
    "        \n",
    "        # calculate item-item similarity matrix\n",
    "        print('calculate item-item similarity matrix...')\n",
    "        # record the calculate time has spent.\n",
    "        \n",
    "        for movie1, related_items in item_similar_matrix.items():\n",
    "            len_user1 = movie_popular[movie1]\n",
    "            for movie2, count in related_items.items():\n",
    "                len_user2 = movie_popular[movie2]\n",
    "                # The similarity of user1 and user2 is len(common movies)/sqrt(len(user1 movies)* len(user2 movies)\n",
    "                item_similar_matrix[movie1][movie2] = count / np.sqrt(len_user1 * len_user2)\n",
    "\n",
    "        \n",
    "        return item_similar_matrix, movie_popular, movie_count\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        Fit the train data by calculate movie similarity matrix.\n",
    "        \"\"\"\n",
    "    \n",
    "        self.item_similar_matix, self.movie_popular, self.movie_count = self.calculate_item_similarity(data)\n",
    "        self.trainset = data\n",
    "        print('Model training finished')\n",
    "        \n",
    "\n",
    "    def recommend(self, user):\n",
    "        \"\"\"\n",
    "        Find K similar movies and recommend N movies for the user\n",
    "        \"\"\"\n",
    "        if not self.item_similar_matix or not self.n_rec_item or not self.trainset or not self.movie_popular or not self.movie_count:\n",
    "            raise NotImplementedError('ItemCF has not init or fit method has not called yet.')\n",
    "        K = self.k_similar_item\n",
    "        N = self.n_rec_item\n",
    "        predict_score = collections.defaultdict(int)\n",
    "\n",
    "        rated_movies = self.trainset[user]\n",
    "        for movie, rating in rated_movies.items():\n",
    "\n",
    "            if movie not in self.item_similar_matix:\n",
    "                print(\"Error: non-existing movie\")\n",
    "                return -1\n",
    "            for related_movie, similarity_factor in sorted(self.item_similar_matix[movie].items(), key=itemgetter(1), reverse=True)[0:K]:\n",
    "                if related_movie in rated_movies:\n",
    "                    continue\n",
    "                predict_score[related_movie] += similarity_factor * rating\n",
    "                \n",
    "\n",
    "        return [movie for movie, _ in sorted(predict_score.items(), key=itemgetter(1), reverse=True)[0:N]]\n",
    "\n",
    "    def test(self, testset):\n",
    "        \"\"\"\n",
    "        Test the recommendation system by recommending scores to all users in testset.\n",
    "        \"\"\"\n",
    "        if not self.n_rec_item or not self.trainset or not self.movie_popular or not self.movie_count:\n",
    "            raise ValueError('ItemCF has not init or fit method has not called yet.')\n",
    "        self.testset = testset\n",
    "        N = self.n_rec_item\n",
    "        \n",
    "        #  varables for precision and recall\n",
    "        hit = 0\n",
    "        rec_count = 0\n",
    "        test_count = 0\n",
    "        \n",
    "        for i, user in enumerate(self.trainset):\n",
    "            test_movies = self.testset.get(user, {})\n",
    "            rec_movies = self.recommend(user)  # type:list\n",
    "            hit += len(set(test_movies).intersection(rec_movies))\n",
    "            \n",
    "            rec_count += N\n",
    "            test_count += len(test_movies)\n",
    "            if i%100==0:\n",
    "                print(f\"Iteration {i} testing performance now....\")\n",
    "            \n",
    "        precision = hit / (1.0 * rec_count)\n",
    "        recall = hit / (1.0 * test_count)\n",
    "        print(f'precision={precision}\\t recall={recall}\\n')\n",
    "\n",
    "        return precision, recall\n",
    "\n",
    "    def predict(self, testset):\n",
    "        \"\"\"\n",
    "        Recommend movies to all users in testset\n",
    "        \"\"\"\n",
    "        items_recommend = defaultdict(list)\n",
    "\n",
    "        for i, user in enumerate(testset):\n",
    "            rec_movies = self.recommend(user)  # type:list\n",
    "            items_recommend[user].append(rec_movies)\n",
    "\n",
    "        return items_recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhhZx4r6NDFf"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "kNtMa0BJKTM_"
   },
   "outputs": [],
   "source": [
    "#convert dataframe into dictionary for model training\n",
    "train_dict, val_dict, test_dict = collections.defaultdict(dict), collections.defaultdict(dict), collections.defaultdict(dict)\n",
    "for user, movie, rate in zip(users_train, movies_train, ratings_train):\n",
    "    train_dict[user][movie]=int(rate)\n",
    "for user, movie, rate in zip(users_val, movies_val, ratings_val):\n",
    "    val_dict[user][movie]=int(rate)\n",
    "for user, movie, rate in zip(users_test, movies_test, ratings_test):\n",
    "    test_dict[user][movie]=int(rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVsdTDcwLVci",
    "outputId": "0727d9fb-e5a3-48b6-8d01-068dfd1a97a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Item-based Collaborative filtering ...\n",
      "\n",
      "generate items co-rated similarity matrix...\n",
      "calculate item-item similarity matrix...\n",
      "Model training finished\n"
     ]
    }
   ],
   "source": [
    "ItemBasedCFModel = ItemBasedCF(20, 10)\n",
    "ItemBasedCFModel.fit(train_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2w_tQx6DQghG"
   },
   "source": [
    "### Model Performance and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwWq6--ZNIo0",
    "outputId": "3fc8a977-cfcc-4272-fa9d-11c0c47d147b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random user 507\n",
      "[5486, 1351, 7668, 7617, 7873, 7999, 6687, 7457, 7210, 1518]\n"
     ]
    }
   ],
   "source": [
    "#check the recommendation of a random user\n",
    "idx=np.random.randint(0,len(users_all))\n",
    "test_user=users_all[idx]\n",
    "print(f\"random user {test_user}\")\n",
    "\n",
    "movies=ItemBasedCFModel.recommend(test_user)\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhEbaNbvQZKc",
    "outputId": "f98b330c-efce-45fe-c87d-ac58bdcbf183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 testing performance now....\n",
      "Iteration 100 testing performance now....\n",
      "Iteration 200 testing performance now....\n",
      "Iteration 300 testing performance now....\n",
      "Iteration 400 testing performance now....\n",
      "Iteration 500 testing performance now....\n",
      "Iteration 600 testing performance now....\n",
      "precision=0.12672131147540983\t recall=0.06012289025433616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate the validation set performance\n",
    "val_prec, val_recall = ItemBasedCFModel.test(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IzKhw6JjQdwx",
    "outputId": "e244f3dd-d1d4-491c-ab51-13f314ff4c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 testing performance now....\n",
      "Iteration 100 testing performance now....\n",
      "Iteration 200 testing performance now....\n",
      "Iteration 300 testing performance now....\n",
      "Iteration 400 testing performance now....\n",
      "Iteration 500 testing performance now....\n",
      "Iteration 600 testing performance now....\n",
      "precision=0.15245901639344261\t recall=0.061483538278460925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate the test set performance\n",
    "test_prec, test_recall = ItemBasedCFModel.test(test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:58:13.546455Z",
     "start_time": "2018-11-14T08:58:13.530833Z"
    },
    "id": "M7t65Y9tbBQq"
   },
   "source": [
    "## 4. Matrix Factorization Model - Using Keras\n",
    "\n",
    "According to Wikipedia, we choose the SVD++ matrix factorzation model denoting the rating $r_{u,i}$ for user $u$ and movie $i$ as \n",
    "\\begin{equation}\n",
    "\t\\hat{r}_{i,u} =\\mu + b_u + b_i + p_u^T q_i\n",
    "\\end{equation}\n",
    "\n",
    "where the parameters are defined as follows:\n",
    "- Mean rating: $\\mu$ is the average rating of all users over all movies in our training\n",
    "-User bias $b_u$ is a per user bias that will be higher for users that give high\n",
    "average ratings to all movies\n",
    "- Item bias $b_i$ is a per item (movie) bias that will be higher for the more popular (higher ranked) movies\n",
    "- User embedding $p_u$ is the a per user F dimensional vector that maps user u into some kind of abstract taste space\n",
    "- Item embedding $q_i$ is a per item F dimensional vector that maps item\n",
    "i into the taste space\n",
    "\n",
    "Our target is to train the interaction terms with embedding dimension $F$ s.t. $p_u$ has $U*F$ coefficients, $p_i$ has $I*F$ coefficients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2eIYdRIbBQw"
   },
   "source": [
    "### Model Implementation using Keras\n",
    "\n",
    "We will implement the matrix factoirzation model \n",
    "\\begin{equation}\n",
    "\t\\Delta \\hat{r}_{i,u} =b_u + b_i + p_u^T q_i\n",
    "\\end{equation}\n",
    "\n",
    "where $  \\Delta \\hat{r}_{i,u} = \\hat{r}_{i,u} - \\mu\n",
    "$ using `keras` layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agekKOdeL40c"
   },
   "source": [
    "We define a callback helper function to show optimization progress every 10 epochs or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MqgWbVN3L3nU"
   },
   "outputs": [],
   "source": [
    "class ReportCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, frequency, use_val=False):\n",
    "        self.freq=frequency\n",
    "        self.use_val=use_val\n",
    "        self.separator=\" || \"\n",
    "        if not(self.use_val):\n",
    "            self.separator=\"\\n\"\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (epoch % self.freq ==0):\n",
    "            train_loss=logs[\"loss\"]\n",
    "            train_error=logs[\"rmse\"]\n",
    "            print(f\"{epoch}: TRAIN Loss {train_loss:.4f},  Err {train_error:.4f}\", end=self.separator)\n",
    "            if self.use_val:\n",
    "                val_loss=logs[\"val_loss\"]\n",
    "                val_error=logs[\"val_rmse\"]\n",
    "                print(f\"VAL Loss {val_loss:.4f}, Err {val_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "id": "gsWXLJXHIy4c"
   },
   "outputs": [],
   "source": [
    "class ReportCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, frequency, use_val=False):\n",
    "        self.freq=frequency\n",
    "        self.use_val=use_val\n",
    "        self.separator=\" || \"\n",
    "        if not(self.use_val):\n",
    "            self.separator=\"\\n\"\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (epoch % self.freq ==0):\n",
    "            train_loss=logs[\"loss\"]\n",
    "            train_error=logs[\"rmse\"]\n",
    "            print(f\"{epoch}: TRAIN Loss {train_loss:.4f},  Err {train_error:.4f}\", end=self.separator)\n",
    "            if self.use_val:\n",
    "                val_loss=logs[\"val_loss\"]\n",
    "                val_error=logs[\"val_rmse\"]\n",
    "                print(f\"VAL Loss {val_loss:.4f}, Err {val_error:.4f}\")\n",
    "\n",
    "\n",
    "#define the collaborative filtering model\n",
    "class MatrixFactorCF:\n",
    "    def __init__(self, u_users, m_items, f_factors, penalty):\n",
    "        \"\"\"\n",
    "        Init Matrix Factorization model\n",
    "        \"\"\"\n",
    "        users=Input(shape=(1,))\n",
    "        movies=Input(shape=(1,))\n",
    "        bu=Embedding(u_users, 1, input_length=1,\n",
    "                    embeddings_initializer=keras.initializers.RandomNormal(stddev=0.0001),)(users)\n",
    "        bm=Embedding(m_items, 1, input_length=1,\n",
    "                    embeddings_initializer=keras.initializers.RandomNormal(stddev=0.0001),)(movies)\n",
    "        pu=Embedding(u_users, f_factors, input_length=1,\n",
    "                    embeddings_initializer=keras.initializers.RandomNormal(stddev=1/np.sqrt(f_factors)),\n",
    "                    embeddings_regularizer=keras.regularizers.l2(penalty),\n",
    "                    name='UserEmbeddingLayer')(users) #add L2 regularization\n",
    "        qm=Embedding(m_items, f_factors, input_length=1,\n",
    "                    embeddings_initializer=keras.initializers.RandomNormal(stddev=1/np.sqrt(f_factors)),\n",
    "                    embeddings_regularizer=keras.regularizers.l2(penalty),\n",
    "                    name='MovieEmbeddingLayer')(movies)\n",
    "        interaction=Dot(axes=-1)([pu,qm])\n",
    "        agg=Add()([bu, bm, interaction])\n",
    "        r_hat=Flatten()(agg)\n",
    "        self.model=Model(inputs=[users,movies], outputs=r_hat)\n",
    "        \n",
    "    \n",
    "    def rmse(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        define the metrics (keras by default will include the penalty on the metrics report)\n",
    "        \"\"\"\n",
    "        return keras.backend.mean(keras.backend.square(y_pred-y_true),axis=-1)\n",
    "\n",
    "    def compile(self, loss='mean_squared_error',verbose=True):\n",
    "        \"\"\" Compile the model \"\"\"\n",
    "        self.model.compile(optimizer=keras.optimizers.Adam(), metrics=[rmse], loss=loss)\n",
    "        if verbose:\n",
    "            self.model.summary()\n",
    "\n",
    "    def fit(self, users_train, movies_train, ratings_train, users_val=None, movies_val=None, ratings_val=None, \n",
    "            verbose=False, epochs=100, batch_size=500):\n",
    "        \"\"\" Fit the model and train \"\"\"\n",
    "        mu=ratings_train.mean()\n",
    "        #save the training paramters\n",
    "        self.mu = mu\n",
    "        self.movies_trainset = np.array(list(set(movies_train))).ravel()\n",
    "\n",
    "        dratings_train = ratings_train-mu\n",
    "        dratings_val = None\n",
    "        if movies_val is not None:\n",
    "            dratings_val = ratings_val-mu\n",
    "        trainset = [users_train, movies_train]\n",
    "        valset = [users_val, movies_val]\n",
    "        history = self.model.fit(trainset, dratings_train, epochs=epochs, batch_size=batch_size, \n",
    "                       callbacks=[ReportCallback(10,True)], verbose=verbose,\n",
    "                        validation_data=(valset, dratings_val))\n",
    "        \n",
    "        self.user_embedding = self.model.get_layer('UserEmbeddingLayer').output\n",
    "        self.movie_embedding = self.model.get_layer('MovieEmbeddingLayer').output\n",
    "        \n",
    "        return history\n",
    "\n",
    "    def predict(self, users_test, movies_test):\n",
    "        \"\"\" Predict the rating for test data (user and movie)\"\"\"\n",
    "        return self.mu+self.model.predict([users_test,movies_test]).ravel()\n",
    "    \n",
    "    def recommend(self, user, N_rec=10):\n",
    "        \"\"\"Recommend movie for users\"\"\"\n",
    "        n_movies = len(self.movies_trainset)\n",
    "        predictions = model.predict(np.array([user]*n_movies).ravel(), self.movies_trainset)\n",
    "        rec_movies = sorted(zip(self.movies_trainset,predictions),key=lambda x: x[1], reverse=True)\n",
    "        return [movie for movie, _ in rec_movies[:N_rec]]\n",
    "\n",
    "    def test_performance(self, trainset, testset):\n",
    "        \"\"\"\n",
    "        Test the recommendation system by recommending scores to all users in testset.\n",
    "        \"\"\"\n",
    "        #  varables for precision and recall\n",
    "        hit = 0\n",
    "        rec_count = 0\n",
    "        test_count = 0\n",
    "        \n",
    "        for i, user in enumerate(trainset):\n",
    "            if user not in testset:\n",
    "                continue\n",
    "            test_movies = testset.get(user, {})\n",
    "            rec_movies = self.recommend(user)  # type:list\n",
    "            hit += len(set(test_movies).intersection(rec_movies))\n",
    "            \n",
    "            rec_count += len(rec_movies)\n",
    "            test_count += len(test_movies)\n",
    "            if i%100==0:\n",
    "                print(f\"Iteration {i} testing performance now....\")\n",
    "            \n",
    "        precision = hit / (1.0 * rec_count)\n",
    "        recall = hit / (1.0 * test_count)\n",
    "        print(f'precision={precision}\\t recall={recall}\\n')\n",
    "        return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T23:20:11.718237Z",
     "start_time": "2019-09-07T23:20:11.625579Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ihTnhaAbBQ0",
    "outputId": "0de13beb-62fd-40cf-eec9-924ba122a169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_109\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_111 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_112 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "UserEmbeddingLayer (Embedding)  (None, 1, 10)        6100        input_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MovieEmbeddingLayer (Embedding) (None, 1, 10)        97240       input_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_205 (Embedding)       (None, 1, 1)         610         input_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_206 (Embedding)       (None, 1, 1)         9724        input_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_54 (Dot)                    (None, 1, 1)         0           UserEmbeddingLayer[0][0]         \n",
      "                                                                 MovieEmbeddingLayer[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 1, 1)         0           embedding_205[0][0]              \n",
      "                                                                 embedding_206[0][0]              \n",
      "                                                                 dot_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_54 (Flatten)            (None, 1)            0           add_54[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 113,674\n",
      "Trainable params: 113,674\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create the model and compile\n",
    "penalty=1e-4\n",
    "F=10\n",
    "MFmodel=MatrixFactorCF(N_users,N_movies, F, penalty)\n",
    "MFmodel.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Sn0l4babBQ9"
   },
   "source": [
    "### Base Model Training\n",
    "\n",
    "Our target is  $  \\Delta \\hat{r}_{i,u} = \\hat{r}_{i,u} - \\mu$, the ratings substracting their sample mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T23:21:47.116901Z",
     "start_time": "2019-09-07T23:20:16.304901Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxjKVv7RbBQ9",
    "outputId": "858584a9-7ad7-4e06-bf00-dfa0a0f108e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: TRAIN Loss 1.9521,  Err 1.1369 || VAL Loss 1.7080, Err 1.0536\n",
      "10: TRAIN Loss 0.7957,  Err 0.7123 || VAL Loss 0.8711, Err 0.7918\n",
      "20: TRAIN Loss 0.6532,  Err 0.5860 || VAL Loss 0.8229, Err 0.7546\n",
      "30: TRAIN Loss 0.5846,  Err 0.4908 || VAL Loss 0.8420, Err 0.7470\n",
      "40: TRAIN Loss 0.5528,  Err 0.4393 || VAL Loss 0.8639, Err 0.7497\n",
      "50: TRAIN Loss 0.5361,  Err 0.4120 || VAL Loss 0.8780, Err 0.7536\n",
      "60: TRAIN Loss 0.5256,  Err 0.3958 || VAL Loss 0.8870, Err 0.7570\n",
      "70: TRAIN Loss 0.5182,  Err 0.3854 || VAL Loss 0.8938, Err 0.7608\n",
      "80: TRAIN Loss 0.5128,  Err 0.3781 || VAL Loss 0.8990, Err 0.7643\n",
      "90: TRAIN Loss 0.5087,  Err 0.3729 || VAL Loss 0.9034, Err 0.7676\n"
     ]
    }
   ],
   "source": [
    "history = MFmodel.fit(users_train, movies_train, ratings_train, users_val, movies_val, ratings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T23:21:49.920125Z",
     "start_time": "2019-09-07T23:21:47.119252Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Pgw-F6fbBRA",
    "outputId": "5bfe10af-52f3-4125-b866-f9e48f3ddeba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.7702070107399355\n"
     ]
    }
   ],
   "source": [
    "Y_pred=MFmodel.predict(users_val,movies_val)\n",
    "loss=np.mean((ratings_val-Y_pred)**2)\n",
    "print(\"validation loss:\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdWqomJmeVfs",
    "outputId": "87a90670-ca27-4e2c-cdae-ac7f3f64d080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random user 609\n",
      "[510, 24, 602, 923, 659, 257, 694, 899, 862, 902]\n"
     ]
    }
   ],
   "source": [
    "#check the recommendation of a random user\n",
    "idx=np.random.randint(0,len(users_all))\n",
    "test_user=users_all[idx]\n",
    "print(f\"random user {test_user}\")\n",
    "\n",
    "movies=MFmodel.recommend(test_user, 10)\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CCN1TAjbBRC"
   },
   "source": [
    "### Hyperparameter search\n",
    "\n",
    "Now we need to find the optimal parameters for the matrix factorization model using grid search, specifically two parameters\n",
    "- Embedding dimension F\n",
    "- Regularization penalty $\\gamma$\n",
    "\n",
    "We use cross validation to evaluate the model performance and choose the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "id": "X4-mTacSY0gs"
   },
   "outputs": [],
   "source": [
    "def grid_search(F_range, penalty_range, steps=200, batch_size=500, verbose=True):\n",
    "    results=[]\n",
    "    best_loss=1e10\n",
    "    best_F=None\n",
    "    best_penalty=None\n",
    "\n",
    "    for F,penalty in itertools.product(F_range, penalty_range):\n",
    "        print(f\"F = {F}, penalty = {penalty} :\")\n",
    "        model=MatrixFactorCF(N_users,N_movies, F, penalty)\n",
    "        model.compile(verbose=verbose)\n",
    "        model.fit(users_train, movies_train, ratings_train, users_val, movies_val, ratings_val, \n",
    "                    verbose=verbose, epochs=steps, batch_size=batch_size)\n",
    "        Y_pred = model.predict(users_val,movies_val)\n",
    "        loss = np.mean((ratings_val-Y_pred)**2)\n",
    "        results.append((F,penalty,loss))\n",
    "        if loss<best_loss:\n",
    "            best_loss=loss\n",
    "            best_F=F\n",
    "            best_penalty=penalty\n",
    "        print(\"\\n\")\n",
    "    print(f\"==> {F},{penalty},{loss} == best ({best_F},{best_penalty},{best_loss}) ===========\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T01:03:36.481009Z",
     "start_time": "2019-09-07T23:21:49.922321Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bYQYDv1bBRC",
    "outputId": "691c8299-2ef8-48fd-fb1b-3746e30986e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F = 10, penalty = 0 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: TRAIN Loss 1.1555,  Err 1.1555 || VAL Loss 1.0833, Err 1.0833\n",
      "10: TRAIN Loss 0.6849,  Err 0.6849 || VAL Loss 0.8394, Err 0.8394\n",
      "20: TRAIN Loss 0.5060,  Err 0.5060 || VAL Loss 0.8491, Err 0.8491\n",
      "30: TRAIN Loss 0.3944,  Err 0.3944 || VAL Loss 0.9026, Err 0.9026\n",
      "40: TRAIN Loss 0.3331,  Err 0.3331 || VAL Loss 0.9529, Err 0.9529\n",
      "50: TRAIN Loss 0.2967,  Err 0.2967 || VAL Loss 0.9939, Err 0.9939\n",
      "60: TRAIN Loss 0.2726,  Err 0.2726 || VAL Loss 1.0296, Err 1.0296\n",
      "70: TRAIN Loss 0.2553,  Err 0.2553 || VAL Loss 1.0642, Err 1.0642\n",
      "80: TRAIN Loss 0.2423,  Err 0.2423 || VAL Loss 1.0983, Err 1.0983\n",
      "90: TRAIN Loss 0.2321,  Err 0.2321 || VAL Loss 1.1333, Err 1.1333\n",
      "\n",
      "\n",
      "F = 10, penalty = 1e-05 :\n",
      "0: TRAIN Loss 1.2308,  Err 1.1431 || VAL Loss 1.1417, Err 1.0634\n",
      "10: TRAIN Loss 0.7264,  Err 0.6832 || VAL Loss 0.8625, Err 0.8198\n",
      "20: TRAIN Loss 0.5431,  Err 0.5012 || VAL Loss 0.8500, Err 0.8079\n",
      "30: TRAIN Loss 0.4356,  Err 0.3896 || VAL Loss 0.8829, Err 0.8368\n",
      "40: TRAIN Loss 0.3794,  Err 0.3308 || VAL Loss 0.9160, Err 0.8673\n",
      "50: TRAIN Loss 0.3474,  Err 0.2974 || VAL Loss 0.9427, Err 0.8925\n",
      "60: TRAIN Loss 0.3272,  Err 0.2763 || VAL Loss 0.9641, Err 0.9130\n",
      "70: TRAIN Loss 0.3133,  Err 0.2617 || VAL Loss 0.9815, Err 0.9298\n",
      "80: TRAIN Loss 0.3031,  Err 0.2510 || VAL Loss 0.9967, Err 0.9445\n",
      "90: TRAIN Loss 0.2953,  Err 0.2427 || VAL Loss 1.0096, Err 0.9570\n",
      "\n",
      "\n",
      "F = 10, penalty = 2e-05 :\n",
      "0: TRAIN Loss 1.3159,  Err 1.1436 || VAL Loss 1.2299, Err 1.0797\n",
      "10: TRAIN Loss 0.7538,  Err 0.6907 || VAL Loss 0.8887, Err 0.8269\n",
      "20: TRAIN Loss 0.5771,  Err 0.5197 || VAL Loss 0.8721, Err 0.8143\n",
      "30: TRAIN Loss 0.4736,  Err 0.4085 || VAL Loss 0.9072, Err 0.8417\n",
      "40: TRAIN Loss 0.4201,  Err 0.3492 || VAL Loss 0.9396, Err 0.8685\n",
      "50: TRAIN Loss 0.3899,  Err 0.3155 || VAL Loss 0.9630, Err 0.8884\n",
      "60: TRAIN Loss 0.3707,  Err 0.2940 || VAL Loss 0.9807, Err 0.9038\n",
      "70: TRAIN Loss 0.3574,  Err 0.2791 || VAL Loss 0.9953, Err 0.9168\n",
      "80: TRAIN Loss 0.3478,  Err 0.2682 || VAL Loss 1.0087, Err 0.9290\n",
      "90: TRAIN Loss 0.3406,  Err 0.2599 || VAL Loss 1.0205, Err 0.9397\n",
      "\n",
      "\n",
      "F = 10, penalty = 5e-05 :\n",
      "0: TRAIN Loss 1.5576,  Err 1.1379 || VAL Loss 1.4128, Err 1.0614\n",
      "10: TRAIN Loss 0.7820,  Err 0.6972 || VAL Loss 0.8865, Err 0.8045\n",
      "20: TRAIN Loss 0.6151,  Err 0.5424 || VAL Loss 0.8532, Err 0.7798\n",
      "30: TRAIN Loss 0.5254,  Err 0.4350 || VAL Loss 0.8853, Err 0.7942\n",
      "40: TRAIN Loss 0.4826,  Err 0.3793 || VAL Loss 0.9185, Err 0.8146\n",
      "50: TRAIN Loss 0.4602,  Err 0.3491 || VAL Loss 0.9416, Err 0.8302\n",
      "60: TRAIN Loss 0.4465,  Err 0.3309 || VAL Loss 0.9563, Err 0.8405\n",
      "70: TRAIN Loss 0.4371,  Err 0.3186 || VAL Loss 0.9663, Err 0.8477\n",
      "80: TRAIN Loss 0.4303,  Err 0.3100 || VAL Loss 0.9729, Err 0.8525\n",
      "90: TRAIN Loss 0.4251,  Err 0.3036 || VAL Loss 0.9778, Err 0.8562\n",
      "\n",
      "\n",
      "F = 10, penalty = 0.0001 :\n",
      "0: TRAIN Loss 1.9555,  Err 1.1375 || VAL Loss 1.7294, Err 1.0718\n",
      "10: TRAIN Loss 0.7958,  Err 0.7109 || VAL Loss 0.8744, Err 0.7936\n",
      "20: TRAIN Loss 0.6531,  Err 0.5845 || VAL Loss 0.8209, Err 0.7513\n",
      "30: TRAIN Loss 0.5867,  Err 0.4932 || VAL Loss 0.8381, Err 0.7434\n",
      "40: TRAIN Loss 0.5550,  Err 0.4424 || VAL Loss 0.8600, Err 0.7468\n",
      "50: TRAIN Loss 0.5379,  Err 0.4149 || VAL Loss 0.8742, Err 0.7508\n",
      "60: TRAIN Loss 0.5271,  Err 0.3984 || VAL Loss 0.8825, Err 0.7537\n",
      "70: TRAIN Loss 0.5195,  Err 0.3876 || VAL Loss 0.8884, Err 0.7564\n",
      "80: TRAIN Loss 0.5140,  Err 0.3801 || VAL Loss 0.8929, Err 0.7589\n",
      "90: TRAIN Loss 0.5098,  Err 0.3746 || VAL Loss 0.8967, Err 0.7614\n",
      "\n",
      "\n",
      "F = 20, penalty = 0 :\n",
      "0: TRAIN Loss 1.1006,  Err 1.1006 || VAL Loss 1.0384, Err 1.0384\n",
      "10: TRAIN Loss 0.5595,  Err 0.5595 || VAL Loss 0.8432, Err 0.8432\n",
      "20: TRAIN Loss 0.3185,  Err 0.3185 || VAL Loss 0.8997, Err 0.8997\n",
      "30: TRAIN Loss 0.2195,  Err 0.2195 || VAL Loss 0.9784, Err 0.9784\n",
      "40: TRAIN Loss 0.1724,  Err 0.1724 || VAL Loss 1.0421, Err 1.0421\n",
      "50: TRAIN Loss 0.1451,  Err 0.1451 || VAL Loss 1.0966, Err 1.0966\n",
      "60: TRAIN Loss 0.1272,  Err 0.1272 || VAL Loss 1.1476, Err 1.1476\n",
      "70: TRAIN Loss 0.1144,  Err 0.1144 || VAL Loss 1.1970, Err 1.1970\n",
      "80: TRAIN Loss 0.1049,  Err 0.1049 || VAL Loss 1.2460, Err 1.2460\n",
      "90: TRAIN Loss 0.0975,  Err 0.0975 || VAL Loss 1.2947, Err 1.2947\n",
      "\n",
      "\n",
      "F = 20, penalty = 1e-05 :\n",
      "0: TRAIN Loss 1.1798,  Err 1.0969 || VAL Loss 1.1024, Err 1.0307\n",
      "10: TRAIN Loss 0.6165,  Err 0.5690 || VAL Loss 0.8709, Err 0.8231\n",
      "20: TRAIN Loss 0.3849,  Err 0.3288 || VAL Loss 0.9049, Err 0.8484\n",
      "30: TRAIN Loss 0.2925,  Err 0.2313 || VAL Loss 0.9580, Err 0.8967\n",
      "40: TRAIN Loss 0.2484,  Err 0.1852 || VAL Loss 0.9975, Err 0.9342\n",
      "50: TRAIN Loss 0.2231,  Err 0.1587 || VAL Loss 1.0296, Err 0.9650\n",
      "60: TRAIN Loss 0.2069,  Err 0.1416 || VAL Loss 1.0568, Err 0.9914\n",
      "70: TRAIN Loss 0.1956,  Err 0.1296 || VAL Loss 1.0812, Err 1.0151\n",
      "80: TRAIN Loss 0.1873,  Err 0.1207 || VAL Loss 1.1038, Err 1.0372\n",
      "90: TRAIN Loss 0.1810,  Err 0.1139 || VAL Loss 1.1239, Err 1.0567\n",
      "\n",
      "\n",
      "F = 20, penalty = 2e-05 :\n",
      "0: TRAIN Loss 1.2618,  Err 1.1005 || VAL Loss 1.1805, Err 1.0454\n",
      "10: TRAIN Loss 0.6472,  Err 0.5779 || VAL Loss 0.8903, Err 0.8208\n",
      "20: TRAIN Loss 0.4234,  Err 0.3395 || VAL Loss 0.9152, Err 0.8306\n",
      "30: TRAIN Loss 0.3344,  Err 0.2398 || VAL Loss 0.9694, Err 0.8743\n",
      "40: TRAIN Loss 0.2939,  Err 0.1939 || VAL Loss 1.0111, Err 0.9109\n",
      "50: TRAIN Loss 0.2715,  Err 0.1686 || VAL Loss 1.0420, Err 0.9389\n",
      "60: TRAIN Loss 0.2575,  Err 0.1529 || VAL Loss 1.0658, Err 0.9610\n",
      "70: TRAIN Loss 0.2479,  Err 0.1421 || VAL Loss 1.0853, Err 0.9794\n",
      "80: TRAIN Loss 0.2409,  Err 0.1344 || VAL Loss 1.1020, Err 0.9953\n",
      "90: TRAIN Loss 0.2356,  Err 0.1285 || VAL Loss 1.1165, Err 1.0093\n",
      "\n",
      "\n",
      "F = 20, penalty = 5e-05 :\n",
      "0: TRAIN Loss 1.4872,  Err 1.0998 || VAL Loss 1.3356, Err 1.0305\n",
      "10: TRAIN Loss 0.7023,  Err 0.6104 || VAL Loss 0.8861, Err 0.7942\n",
      "20: TRAIN Loss 0.5090,  Err 0.3903 || VAL Loss 0.8967, Err 0.7764\n",
      "30: TRAIN Loss 0.4367,  Err 0.2937 || VAL Loss 0.9449, Err 0.8010\n",
      "40: TRAIN Loss 0.4051,  Err 0.2492 || VAL Loss 0.9796, Err 0.8232\n",
      "50: TRAIN Loss 0.3877,  Err 0.2250 || VAL Loss 1.0008, Err 0.8377\n",
      "60: TRAIN Loss 0.3764,  Err 0.2103 || VAL Loss 1.0138, Err 0.8474\n",
      "70: TRAIN Loss 0.3684,  Err 0.2002 || VAL Loss 1.0225, Err 0.8542\n",
      "80: TRAIN Loss 0.3623,  Err 0.1931 || VAL Loss 1.0288, Err 0.8594\n",
      "90: TRAIN Loss 0.3577,  Err 0.1878 || VAL Loss 1.0342, Err 0.8641\n",
      "\n",
      "\n",
      "F = 20, penalty = 0.0001 :\n",
      "0: TRAIN Loss 1.8473,  Err 1.0968 || VAL Loss 1.5824, Err 1.0253\n",
      "10: TRAIN Loss 0.7405,  Err 0.6521 || VAL Loss 0.8688, Err 0.7810\n",
      "20: TRAIN Loss 0.5975,  Err 0.4770 || VAL Loss 0.8663, Err 0.7437\n",
      "30: TRAIN Loss 0.5436,  Err 0.3881 || VAL Loss 0.9020, Err 0.7454\n",
      "40: TRAIN Loss 0.5189,  Err 0.3460 || VAL Loss 0.9242, Err 0.7508\n",
      "50: TRAIN Loss 0.5045,  Err 0.3237 || VAL Loss 0.9357, Err 0.7548\n",
      "60: TRAIN Loss 0.4948,  Err 0.3104 || VAL Loss 0.9424, Err 0.7578\n",
      "70: TRAIN Loss 0.4879,  Err 0.3015 || VAL Loss 0.9472, Err 0.7608\n",
      "80: TRAIN Loss 0.4828,  Err 0.2955 || VAL Loss 0.9508, Err 0.7634\n",
      "90: TRAIN Loss 0.4789,  Err 0.2909 || VAL Loss 0.9541, Err 0.7660\n",
      "\n",
      "\n",
      "F = 25, penalty = 0 :\n",
      "0: TRAIN Loss 1.0965,  Err 1.0965 || VAL Loss 1.0359, Err 1.0359\n",
      "10: TRAIN Loss 0.5115,  Err 0.5115 || VAL Loss 0.8516, Err 0.8516\n",
      "20: TRAIN Loss 0.2642,  Err 0.2642 || VAL Loss 0.9205, Err 0.9205\n",
      "30: TRAIN Loss 0.1733,  Err 0.1733 || VAL Loss 1.0024, Err 1.0024\n",
      "40: TRAIN Loss 0.1307,  Err 0.1307 || VAL Loss 1.0710, Err 1.0710\n",
      "50: TRAIN Loss 0.1060,  Err 0.1060 || VAL Loss 1.1331, Err 1.1331\n",
      "60: TRAIN Loss 0.0898,  Err 0.0898 || VAL Loss 1.1918, Err 1.1918\n",
      "70: TRAIN Loss 0.0784,  Err 0.0784 || VAL Loss 1.2488, Err 1.2488\n",
      "80: TRAIN Loss 0.0699,  Err 0.0699 || VAL Loss 1.3023, Err 1.3023\n",
      "90: TRAIN Loss 0.0634,  Err 0.0634 || VAL Loss 1.3546, Err 1.3546\n",
      "\n",
      "\n",
      "F = 25, penalty = 1e-05 :\n",
      "0: TRAIN Loss 1.1740,  Err 1.0921 || VAL Loss 1.0924, Err 1.0226\n",
      "10: TRAIN Loss 0.5652,  Err 0.5150 || VAL Loss 0.8629, Err 0.8121\n",
      "20: TRAIN Loss 0.3306,  Err 0.2692 || VAL Loss 0.8992, Err 0.8374\n",
      "30: TRAIN Loss 0.2450,  Err 0.1788 || VAL Loss 0.9559, Err 0.8896\n",
      "40: TRAIN Loss 0.2054,  Err 0.1375 || VAL Loss 1.0000, Err 0.9320\n",
      "50: TRAIN Loss 0.1829,  Err 0.1142 || VAL Loss 1.0354, Err 0.9666\n",
      "60: TRAIN Loss 0.1684,  Err 0.0991 || VAL Loss 1.0657, Err 0.9963\n",
      "70: TRAIN Loss 0.1585,  Err 0.0888 || VAL Loss 1.0927, Err 1.0229\n",
      "80: TRAIN Loss 0.1514,  Err 0.0815 || VAL Loss 1.1163, Err 1.0462\n",
      "90: TRAIN Loss 0.1461,  Err 0.0759 || VAL Loss 1.1380, Err 1.0678\n",
      "\n",
      "\n",
      "F = 25, penalty = 2e-05 :\n",
      "0: TRAIN Loss 1.2498,  Err 1.0916 || VAL Loss 1.1561, Err 1.0259\n",
      "10: TRAIN Loss 0.6081,  Err 0.5349 || VAL Loss 0.8932, Err 0.8193\n",
      "20: TRAIN Loss 0.3773,  Err 0.2847 || VAL Loss 0.9386, Err 0.8452\n",
      "30: TRAIN Loss 0.2952,  Err 0.1919 || VAL Loss 0.9953, Err 0.8915\n",
      "40: TRAIN Loss 0.2588,  Err 0.1505 || VAL Loss 1.0348, Err 0.9261\n",
      "50: TRAIN Loss 0.2388,  Err 0.1278 || VAL Loss 1.0635, Err 0.9523\n",
      "60: TRAIN Loss 0.2261,  Err 0.1137 || VAL Loss 1.0868, Err 0.9742\n",
      "70: TRAIN Loss 0.2173,  Err 0.1040 || VAL Loss 1.1064, Err 0.9930\n",
      "80: TRAIN Loss 0.2108,  Err 0.0970 || VAL Loss 1.1229, Err 1.0090\n",
      "90: TRAIN Loss 0.2058,  Err 0.0917 || VAL Loss 1.1377, Err 1.0234\n",
      "\n",
      "\n",
      "F = 25, penalty = 5e-05 :\n",
      "0: TRAIN Loss 1.4695,  Err 1.0910 || VAL Loss 1.3130, Err 1.0217\n",
      "10: TRAIN Loss 0.6686,  Err 0.5701 || VAL Loss 0.8824, Err 0.7829\n",
      "20: TRAIN Loss 0.4757,  Err 0.3399 || VAL Loss 0.9038, Err 0.7663\n",
      "30: TRAIN Loss 0.4098,  Err 0.2486 || VAL Loss 0.9484, Err 0.7863\n",
      "40: TRAIN Loss 0.3815,  Err 0.2080 || VAL Loss 0.9787, Err 0.8046\n",
      "50: TRAIN Loss 0.3657,  Err 0.1864 || VAL Loss 0.9990, Err 0.8192\n",
      "60: TRAIN Loss 0.3552,  Err 0.1730 || VAL Loss 1.0133, Err 0.8309\n",
      "70: TRAIN Loss 0.3476,  Err 0.1643 || VAL Loss 1.0248, Err 0.8413\n",
      "80: TRAIN Loss 0.3419,  Err 0.1579 || VAL Loss 1.0344, Err 0.8502\n",
      "90: TRAIN Loss 0.3374,  Err 0.1530 || VAL Loss 1.0429, Err 0.8583\n",
      "\n",
      "\n",
      "F = 25, penalty = 0.0001 :\n",
      "0: TRAIN Loss 1.8163,  Err 1.0906 || VAL Loss 1.5421, Err 1.0199\n",
      "10: TRAIN Loss 0.7248,  Err 0.6328 || VAL Loss 0.8728, Err 0.7802\n",
      "20: TRAIN Loss 0.5785,  Err 0.4387 || VAL Loss 0.8856, Err 0.7434\n",
      "30: TRAIN Loss 0.5300,  Err 0.3546 || VAL Loss 0.9215, Err 0.7449\n",
      "40: TRAIN Loss 0.5078,  Err 0.3161 || VAL Loss 0.9410, Err 0.7487\n",
      "50: TRAIN Loss 0.4945,  Err 0.2955 || VAL Loss 0.9518, Err 0.7525\n",
      "60: TRAIN Loss 0.4855,  Err 0.2833 || VAL Loss 0.9586, Err 0.7561\n",
      "70: TRAIN Loss 0.4791,  Err 0.2752 || VAL Loss 0.9639, Err 0.7599\n",
      "80: TRAIN Loss 0.4743,  Err 0.2697 || VAL Loss 0.9682, Err 0.7634\n",
      "90: TRAIN Loss 0.4706,  Err 0.2655 || VAL Loss 0.9718, Err 0.7666\n",
      "\n",
      "\n",
      "F = 50, penalty = 0 :\n",
      "0: TRAIN Loss 1.0788,  Err 1.0788 || VAL Loss 1.0133, Err 1.0133\n",
      "10: TRAIN Loss 0.3192,  Err 0.3192 || VAL Loss 0.8488, Err 0.8488\n",
      "20: TRAIN Loss 0.1042,  Err 0.1042 || VAL Loss 0.9391, Err 0.9391\n",
      "30: TRAIN Loss 0.0485,  Err 0.0485 || VAL Loss 1.0155, Err 1.0155\n",
      "40: TRAIN Loss 0.0265,  Err 0.0265 || VAL Loss 1.0762, Err 1.0762\n",
      "50: TRAIN Loss 0.0158,  Err 0.0158 || VAL Loss 1.1274, Err 1.1274\n",
      "60: TRAIN Loss 0.0101,  Err 0.0101 || VAL Loss 1.1706, Err 1.1706\n",
      "70: TRAIN Loss 0.0069,  Err 0.0069 || VAL Loss 1.2092, Err 1.2092\n",
      "80: TRAIN Loss 0.0050,  Err 0.0050 || VAL Loss 1.2403, Err 1.2403\n",
      "90: TRAIN Loss 0.0039,  Err 0.0039 || VAL Loss 1.2652, Err 1.2652\n",
      "\n",
      "\n",
      "F = 50, penalty = 1e-05 :\n",
      "0: TRAIN Loss 1.1509,  Err 1.0744 || VAL Loss 1.0753, Err 1.0126\n",
      "10: TRAIN Loss 0.3909,  Err 0.3289 || VAL Loss 0.8805, Err 0.8173\n",
      "20: TRAIN Loss 0.1873,  Err 0.1117 || VAL Loss 0.9485, Err 0.8725\n",
      "30: TRAIN Loss 0.1332,  Err 0.0555 || VAL Loss 0.9946, Err 0.9168\n",
      "40: TRAIN Loss 0.1112,  Err 0.0340 || VAL Loss 1.0216, Err 0.9443\n",
      "50: TRAIN Loss 0.0999,  Err 0.0239 || VAL Loss 1.0404, Err 0.9642\n",
      "60: TRAIN Loss 0.0932,  Err 0.0184 || VAL Loss 1.0560, Err 0.9810\n",
      "70: TRAIN Loss 0.0887,  Err 0.0150 || VAL Loss 1.0685, Err 0.9945\n",
      "80: TRAIN Loss 0.0857,  Err 0.0129 || VAL Loss 1.0792, Err 1.0061\n",
      "90: TRAIN Loss 0.0834,  Err 0.0115 || VAL Loss 1.0874, Err 1.0152\n",
      "\n",
      "\n",
      "F = 50, penalty = 2e-05 :\n",
      "0: TRAIN Loss 1.2216,  Err 1.0756 || VAL Loss 1.1241, Err 1.0102\n",
      "10: TRAIN Loss 0.4457,  Err 0.3517 || VAL Loss 0.8966, Err 0.8004\n",
      "20: TRAIN Loss 0.2510,  Err 0.1300 || VAL Loss 0.9634, Err 0.8415\n",
      "30: TRAIN Loss 0.1993,  Err 0.0712 || VAL Loss 1.0088, Err 0.8803\n",
      "40: TRAIN Loss 0.1780,  Err 0.0488 || VAL Loss 1.0346, Err 0.9051\n",
      "50: TRAIN Loss 0.1664,  Err 0.0378 || VAL Loss 1.0511, Err 0.9222\n",
      "60: TRAIN Loss 0.1590,  Err 0.0318 || VAL Loss 1.0620, Err 0.9344\n",
      "70: TRAIN Loss 0.1541,  Err 0.0282 || VAL Loss 1.0698, Err 0.9436\n",
      "80: TRAIN Loss 0.1505,  Err 0.0259 || VAL Loss 1.0761, Err 0.9511\n",
      "90: TRAIN Loss 0.1478,  Err 0.0242 || VAL Loss 1.0810, Err 0.9570\n",
      "\n",
      "\n",
      "F = 50, penalty = 5e-05 :\n",
      "0: TRAIN Loss 1.4126,  Err 1.0723 || VAL Loss 1.2502, Err 1.0084\n",
      "10: TRAIN Loss 0.5548,  Err 0.4214 || VAL Loss 0.9149, Err 0.7775\n",
      "20: TRAIN Loss 0.3907,  Err 0.1994 || VAL Loss 0.9776, Err 0.7844\n",
      "30: TRAIN Loss 0.3474,  Err 0.1351 || VAL Loss 1.0152, Err 0.8019\n",
      "40: TRAIN Loss 0.3285,  Err 0.1103 || VAL Loss 1.0304, Err 0.8116\n",
      "50: TRAIN Loss 0.3171,  Err 0.0983 || VAL Loss 1.0364, Err 0.8172\n",
      "60: TRAIN Loss 0.3095,  Err 0.0919 || VAL Loss 1.0386, Err 0.8204\n",
      "70: TRAIN Loss 0.3041,  Err 0.0878 || VAL Loss 1.0396, Err 0.8229\n",
      "80: TRAIN Loss 0.3000,  Err 0.0849 || VAL Loss 1.0407, Err 0.8252\n",
      "90: TRAIN Loss 0.2969,  Err 0.0828 || VAL Loss 1.0418, Err 0.8273\n",
      "\n",
      "\n",
      "F = 50, penalty = 0.0001 :\n",
      "0: TRAIN Loss 1.7114,  Err 1.0717 || VAL Loss 1.4152, Err 1.0057\n",
      "10: TRAIN Loss 0.6570,  Err 0.5253 || VAL Loss 0.8852, Err 0.7491\n",
      "20: TRAIN Loss 0.5395,  Err 0.3336 || VAL Loss 0.9341, Err 0.7257\n",
      "30: TRAIN Loss 0.5049,  Err 0.2705 || VAL Loss 0.9604, Err 0.7251\n",
      "40: TRAIN Loss 0.4873,  Err 0.2443 || VAL Loss 0.9694, Err 0.7260\n",
      "50: TRAIN Loss 0.4761,  Err 0.2311 || VAL Loss 0.9725, Err 0.7273\n",
      "60: TRAIN Loss 0.4686,  Err 0.2237 || VAL Loss 0.9747, Err 0.7297\n",
      "70: TRAIN Loss 0.4631,  Err 0.2191 || VAL Loss 0.9768, Err 0.7325\n",
      "80: TRAIN Loss 0.4591,  Err 0.2156 || VAL Loss 0.9791, Err 0.7356\n",
      "90: TRAIN Loss 0.4560,  Err 0.2133 || VAL Loss 0.9813, Err 0.7385\n",
      "\n",
      "\n",
      "F = 100, penalty = 0 :\n",
      "0: TRAIN Loss 1.0679,  Err 1.0679 || VAL Loss 1.0024, Err 1.0024\n",
      "10: TRAIN Loss 0.1389,  Err 0.1389 || VAL Loss 0.8425, Err 0.8425\n",
      "20: TRAIN Loss 0.0189,  Err 0.0189 || VAL Loss 0.9182, Err 0.9182\n",
      "30: TRAIN Loss 0.0047,  Err 0.0047 || VAL Loss 0.9521, Err 0.9521\n",
      "40: TRAIN Loss 0.0029,  Err 0.0029 || VAL Loss 0.9612, Err 0.9612\n",
      "50: TRAIN Loss 0.0030,  Err 0.0030 || VAL Loss 0.9579, Err 0.9579\n",
      "60: TRAIN Loss 0.0030,  Err 0.0030 || VAL Loss 0.9498, Err 0.9498\n",
      "70: TRAIN Loss 0.0029,  Err 0.0029 || VAL Loss 0.9421, Err 0.9421\n",
      "80: TRAIN Loss 0.0028,  Err 0.0028 || VAL Loss 0.9347, Err 0.9347\n",
      "90: TRAIN Loss 0.0026,  Err 0.0026 || VAL Loss 0.9285, Err 0.9285\n",
      "\n",
      "\n",
      "F = 100, penalty = 1e-05 :\n",
      "0: TRAIN Loss 1.1378,  Err 1.0671 || VAL Loss 1.0573, Err 1.0018\n",
      "10: TRAIN Loss 0.2302,  Err 0.1538 || VAL Loss 0.8808, Err 0.8030\n",
      "20: TRAIN Loss 0.1106,  Err 0.0263 || VAL Loss 0.9254, Err 0.8410\n",
      "30: TRAIN Loss 0.0917,  Err 0.0110 || VAL Loss 0.9286, Err 0.8478\n",
      "40: TRAIN Loss 0.0851,  Err 0.0085 || VAL Loss 0.9156, Err 0.8387\n",
      "50: TRAIN Loss 0.0815,  Err 0.0080 || VAL Loss 0.8987, Err 0.8248\n",
      "60: TRAIN Loss 0.0789,  Err 0.0077 || VAL Loss 0.8851, Err 0.8133\n",
      "70: TRAIN Loss 0.0770,  Err 0.0075 || VAL Loss 0.8748, Err 0.8047\n",
      "80: TRAIN Loss 0.0756,  Err 0.0074 || VAL Loss 0.8678, Err 0.7989\n",
      "90: TRAIN Loss 0.0745,  Err 0.0072 || VAL Loss 0.8634, Err 0.7955\n",
      "\n",
      "\n",
      "F = 100, penalty = 2e-05 :\n",
      "0: TRAIN Loss 1.1978,  Err 1.0661 || VAL Loss 1.0999, Err 1.0031\n",
      "10: TRAIN Loss 0.2959,  Err 0.1753 || VAL Loss 0.9168, Err 0.7936\n",
      "20: TRAIN Loss 0.1804,  Err 0.0407 || VAL Loss 0.9630, Err 0.8227\n",
      "30: TRAIN Loss 0.1600,  Err 0.0225 || VAL Loss 0.9638, Err 0.8257\n",
      "40: TRAIN Loss 0.1514,  Err 0.0185 || VAL Loss 0.9515, Err 0.8180\n",
      "50: TRAIN Loss 0.1461,  Err 0.0174 || VAL Loss 0.9380, Err 0.8084\n",
      "60: TRAIN Loss 0.1423,  Err 0.0166 || VAL Loss 0.9276, Err 0.8011\n",
      "70: TRAIN Loss 0.1395,  Err 0.0162 || VAL Loss 0.9213, Err 0.7971\n",
      "80: TRAIN Loss 0.1375,  Err 0.0159 || VAL Loss 0.9170, Err 0.7944\n",
      "90: TRAIN Loss 0.1360,  Err 0.0157 || VAL Loss 0.9145, Err 0.7931\n",
      "\n",
      "\n",
      "F = 100, penalty = 5e-05 :\n",
      "0: TRAIN Loss 1.3638,  Err 1.0657 || VAL Loss 1.1938, Err 1.0011\n",
      "10: TRAIN Loss 0.4481,  Err 0.2640 || VAL Loss 0.9433, Err 0.7538\n",
      "20: TRAIN Loss 0.3460,  Err 0.1101 || VAL Loss 0.9906, Err 0.7530\n",
      "30: TRAIN Loss 0.3231,  Err 0.0825 || VAL Loss 0.9917, Err 0.7505\n",
      "40: TRAIN Loss 0.3110,  Err 0.0750 || VAL Loss 0.9845, Err 0.7475\n",
      "50: TRAIN Loss 0.3029,  Err 0.0713 || VAL Loss 0.9786, Err 0.7462\n",
      "60: TRAIN Loss 0.2975,  Err 0.0698 || VAL Loss 0.9760, Err 0.7471\n",
      "70: TRAIN Loss 0.2935,  Err 0.0684 || VAL Loss 0.9743, Err 0.7481\n",
      "80: TRAIN Loss 0.2905,  Err 0.0674 || VAL Loss 0.9745, Err 0.7505\n",
      "90: TRAIN Loss 0.2883,  Err 0.0669 || VAL Loss 0.9753, Err 0.7529\n",
      "\n",
      "\n",
      "F = 100, penalty = 0.0001 :\n",
      "0: TRAIN Loss 1.6114,  Err 1.0637 || VAL Loss 1.2990, Err 0.9961\n",
      "10: TRAIN Loss 0.6048,  Err 0.4132 || VAL Loss 0.9300, Err 0.7322\n",
      "20: TRAIN Loss 0.5236,  Err 0.2636 || VAL Loss 0.9794, Err 0.7174\n",
      "30: TRAIN Loss 0.4986,  Err 0.2277 || VAL Loss 0.9870, Err 0.7153\n",
      "40: TRAIN Loss 0.4844,  Err 0.2152 || VAL Loss 0.9858, Err 0.7160\n",
      "50: TRAIN Loss 0.4751,  Err 0.2092 || VAL Loss 0.9846, Err 0.7185\n",
      "60: TRAIN Loss 0.4685,  Err 0.2057 || VAL Loss 0.9842, Err 0.7215\n",
      "70: TRAIN Loss 0.4639,  Err 0.2040 || VAL Loss 0.9852, Err 0.7250\n",
      "80: TRAIN Loss 0.4604,  Err 0.2026 || VAL Loss 0.9865, Err 0.7281\n",
      "90: TRAIN Loss 0.4578,  Err 0.2015 || VAL Loss 0.9876, Err 0.7311\n",
      "\n",
      "\n",
      "F = 150, penalty = 0 :\n",
      "0: TRAIN Loss 1.0650,  Err 1.0650 || VAL Loss 1.0000, Err 1.0000\n",
      "10: TRAIN Loss 0.0652,  Err 0.0652 || VAL Loss 0.8331, Err 0.8331\n",
      "20: TRAIN Loss 0.0057,  Err 0.0057 || VAL Loss 0.8736, Err 0.8736\n",
      "30: TRAIN Loss 0.0034,  Err 0.0034 || VAL Loss 0.8779, Err 0.8779\n",
      "40: TRAIN Loss 0.0038,  Err 0.0038 || VAL Loss 0.8718, Err 0.8718\n",
      "50: TRAIN Loss 0.0040,  Err 0.0040 || VAL Loss 0.8630, Err 0.8630\n",
      "60: TRAIN Loss 0.0038,  Err 0.0038 || VAL Loss 0.8547, Err 0.8547\n",
      "70: TRAIN Loss 0.0036,  Err 0.0036 || VAL Loss 0.8487, Err 0.8487\n",
      "80: TRAIN Loss 0.0035,  Err 0.0035 || VAL Loss 0.8429, Err 0.8429\n",
      "90: TRAIN Loss 0.0033,  Err 0.0033 || VAL Loss 0.8379, Err 0.8379\n",
      "\n",
      "\n",
      "F = 150, penalty = 1e-05 :\n",
      "0: TRAIN Loss 1.1299,  Err 1.0627 || VAL Loss 1.0516, Err 1.0001\n",
      "10: TRAIN Loss 0.1634,  Err 0.0792 || VAL Loss 0.8900, Err 0.8048\n",
      "20: TRAIN Loss 0.0975,  Err 0.0124 || VAL Loss 0.9022, Err 0.8171\n",
      "30: TRAIN Loss 0.0887,  Err 0.0095 || VAL Loss 0.8814, Err 0.8018\n",
      "40: TRAIN Loss 0.0844,  Err 0.0094 || VAL Loss 0.8588, Err 0.7833\n",
      "50: TRAIN Loss 0.0813,  Err 0.0092 || VAL Loss 0.8434, Err 0.7706\n",
      "60: TRAIN Loss 0.0790,  Err 0.0089 || VAL Loss 0.8347, Err 0.7639\n",
      "70: TRAIN Loss 0.0774,  Err 0.0087 || VAL Loss 0.8301, Err 0.7606\n",
      "80: TRAIN Loss 0.0761,  Err 0.0085 || VAL Loss 0.8276, Err 0.7592\n",
      "90: TRAIN Loss 0.0751,  Err 0.0083 || VAL Loss 0.8278, Err 0.7602\n",
      "\n",
      "\n",
      "F = 150, penalty = 2e-05 :\n",
      "0: TRAIN Loss 1.1861,  Err 1.0633 || VAL Loss 1.0865, Err 0.9993\n",
      "10: TRAIN Loss 0.2381,  Err 0.1028 || VAL Loss 0.9201, Err 0.7824\n",
      "20: TRAIN Loss 0.1687,  Err 0.0247 || VAL Loss 0.9363, Err 0.7917\n",
      "30: TRAIN Loss 0.1568,  Err 0.0192 || VAL Loss 0.9160, Err 0.7776\n",
      "40: TRAIN Loss 0.1500,  Err 0.0182 || VAL Loss 0.8965, Err 0.7636\n",
      "50: TRAIN Loss 0.1455,  Err 0.0177 || VAL Loss 0.8851, Err 0.7560\n",
      "60: TRAIN Loss 0.1421,  Err 0.0172 || VAL Loss 0.8797, Err 0.7535\n",
      "70: TRAIN Loss 0.1396,  Err 0.0168 || VAL Loss 0.8777, Err 0.7536\n",
      "80: TRAIN Loss 0.1378,  Err 0.0165 || VAL Loss 0.8769, Err 0.7542\n",
      "90: TRAIN Loss 0.1365,  Err 0.0163 || VAL Loss 0.8780, Err 0.7565\n",
      "\n",
      "\n",
      "F = 150, penalty = 5e-05 :\n",
      "0: TRAIN Loss 1.3344,  Err 1.0625 || VAL Loss 1.1618, Err 0.9966\n",
      "10: TRAIN Loss 0.4070,  Err 0.1927 || VAL Loss 0.9647, Err 0.7451\n",
      "20: TRAIN Loss 0.3390,  Err 0.0886 || VAL Loss 0.9919, Err 0.7400\n",
      "30: TRAIN Loss 0.3212,  Err 0.0751 || VAL Loss 0.9810, Err 0.7335\n",
      "40: TRAIN Loss 0.3106,  Err 0.0716 || VAL Loss 0.9719, Err 0.7313\n",
      "50: TRAIN Loss 0.3035,  Err 0.0696 || VAL Loss 0.9668, Err 0.7316\n",
      "60: TRAIN Loss 0.2985,  Err 0.0684 || VAL Loss 0.9659, Err 0.7343\n",
      "70: TRAIN Loss 0.2949,  Err 0.0677 || VAL Loss 0.9662, Err 0.7375\n",
      "80: TRAIN Loss 0.2924,  Err 0.0672 || VAL Loss 0.9674, Err 0.7408\n",
      "90: TRAIN Loss 0.2902,  Err 0.0664 || VAL Loss 0.9692, Err 0.7441\n",
      "\n",
      "\n",
      "F = 150, penalty = 0.0001 :\n",
      "0: TRAIN Loss 1.5521,  Err 1.0621 || VAL Loss 1.2401, Err 0.9945\n",
      "10: TRAIN Loss 0.5881,  Err 0.3608 || VAL Loss 0.9616, Err 0.7281\n",
      "20: TRAIN Loss 0.5239,  Err 0.2431 || VAL Loss 0.9959, Err 0.7135\n",
      "30: TRAIN Loss 0.5011,  Err 0.2196 || VAL Loss 0.9938, Err 0.7119\n",
      "40: TRAIN Loss 0.4878,  Err 0.2122 || VAL Loss 0.9899, Err 0.7137\n",
      "50: TRAIN Loss 0.4788,  Err 0.2086 || VAL Loss 0.9878, Err 0.7167\n",
      "60: TRAIN Loss 0.4726,  Err 0.2061 || VAL Loss 0.9872, Err 0.7205\n",
      "70: TRAIN Loss 0.4680,  Err 0.2051 || VAL Loss 0.9876, Err 0.7242\n",
      "80: TRAIN Loss 0.4646,  Err 0.2038 || VAL Loss 0.9885, Err 0.7274\n",
      "90: TRAIN Loss 0.4620,  Err 0.2034 || VAL Loss 0.9897, Err 0.7305\n",
      "\n",
      "\n",
      "==> 150,0.0001,0.733319885460423 == best (150,0.0001,0.733319885460423) ===========\n"
     ]
    }
   ],
   "source": [
    "steps=100\n",
    "F_range=[10,20,25,50,100,150]\n",
    "penalty_range=[0,1e-5,2e-5,5e-5,1e-4]\n",
    "\n",
    "results=grid_search(F_range, penalty_range, steps, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T01:03:36.508243Z",
     "start_time": "2019-09-08T01:03:36.488821Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "cvo4mTojbBRI",
    "outputId": "7fdee0bc-0e07-46d0-a8ed-e824f780acc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best F 100.0, best penalty 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row4_col4{\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002\" ><thead>    <tr>        <th class=\"index_name level0\" >penalty</th>        <th class=\"col_heading level0 col0\" >0.0</th>        <th class=\"col_heading level0 col1\" >1e-05</th>        <th class=\"col_heading level0 col2\" >2e-05</th>        <th class=\"col_heading level0 col3\" >5e-05</th>        <th class=\"col_heading level0 col4\" >0.0001</th>    </tr>    <tr>        <th class=\"index_name level0\" >F</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >10</th>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row0_col0\" class=\"data row0 col0\" >1.165259</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.967877</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.948778</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row0_col3\" class=\"data row0 col3\" >0.858901</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row0_col4\" class=\"data row0 col4\" >0.763371</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >20</th>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row1_col0\" class=\"data row1 col0\" >1.338170</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row1_col1\" class=\"data row1 col1\" >1.072398</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row1_col2\" class=\"data row1 col2\" >1.019727</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row1_col3\" class=\"data row1 col3\" >0.867622</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row1_col4\" class=\"data row1 col4\" >0.768261</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >25</th>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row2_col0\" class=\"data row2 col0\" >1.400793</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row2_col1\" class=\"data row2 col1\" >1.085025</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row2_col2\" class=\"data row2 col2\" >1.034732</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row2_col3\" class=\"data row2 col3\" >0.865184</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row2_col4\" class=\"data row2 col4\" >0.769668</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >50</th>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row3_col0\" class=\"data row3 col0\" >1.283078</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row3_col1\" class=\"data row3 col1\" >1.022205</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row3_col2\" class=\"data row3 col2\" >0.961770</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row3_col3\" class=\"data row3 col3\" >0.829193</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row3_col4\" class=\"data row3 col4\" >0.741140</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >100</th>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row4_col0\" class=\"data row4 col0\" >0.923903</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row4_col1\" class=\"data row4 col1\" >0.793229</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row4_col2\" class=\"data row4 col2\" >0.792795</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row4_col3\" class=\"data row4 col3\" >0.755192</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row4_col4\" class=\"data row4 col4\" >0.733857</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >150</th>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row5_col0\" class=\"data row5 col0\" >0.833513</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row5_col1\" class=\"data row5 col1\" >0.761243</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row5_col2\" class=\"data row5 col2\" >0.759424</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row5_col3\" class=\"data row5 col3\" >0.746875</td>\n",
       "                        <td id=\"T_4c226900_1fe4_11eb_a8e1_0242ac1c0002row5_col4\" class=\"data row5 col4\" >0.734320</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f35118d7b70>"
      ]
     },
     "execution_count": 344,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df=pd.DataFrame(results,columns=[\"F\",\"penalty\",\"val_rmse\"])\n",
    "summary=pd.pivot_table(result_df, index=\"F\",columns=\"penalty\",values=\"val_rmse\")\n",
    "\n",
    "#find the best parameters\n",
    "best=result_df.iloc[result_df[\"val_rmse\"].idxmin()]\n",
    "print(f\"best F {best['F']}, best penalty {best['penalty']}\")\n",
    "\n",
    "cm = sns.light_palette(\"#60FF60\", reverse=True, as_cmap=True)\n",
    "s = summary.style.highlight_min(axis=None)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7ED5Y4abBRa"
   },
   "source": [
    "Best model has $F=100$ and $\\gamma=1e-4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHHR4kuxbBRa"
   },
   "source": [
    "### Model Performance and Prediction\n",
    "\n",
    "Using the best parameters obtained above, we re-train the model on the whole dataset and evaluate its performance on the test dataset. We also make movie recommendation based on the model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T01:19:02.399069Z",
     "start_time": "2019-09-08T01:16:42.130369Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZJUo6EmbBRf",
    "outputId": "2e184983-3ec4-4f22-e047-6ffc79805b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_203\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_205 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_206 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "UserEmbeddingLayer (Embedding)  (None, 1, 100)       61000       input_205[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MovieEmbeddingLayer (Embedding) (None, 1, 100)       972400      input_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_299 (Embedding)       (None, 1, 1)         610         input_205[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_300 (Embedding)       (None, 1, 1)         9724        input_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_101 (Dot)                   (None, 1, 1)         0           UserEmbeddingLayer[0][0]         \n",
      "                                                                 MovieEmbeddingLayer[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 1, 1)         0           embedding_299[0][0]              \n",
      "                                                                 embedding_300[0][0]              \n",
      "                                                                 dot_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_101 (Flatten)           (None, 1)            0           add_101[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,043,734\n",
      "Trainable params: 1,043,734\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: TRAIN Loss 1.5637,  Err 1.0553 || VAL Loss 1.2692, Err 1.0050\n",
      "10: TRAIN Loss 0.6114,  Err 0.4229 || VAL Loss 0.9188, Err 0.7242\n",
      "20: TRAIN Loss 0.5413,  Err 0.2888 || VAL Loss 0.9642, Err 0.7099\n",
      "30: TRAIN Loss 0.5183,  Err 0.2558 || VAL Loss 0.9717, Err 0.7086\n",
      "40: TRAIN Loss 0.5054,  Err 0.2443 || VAL Loss 0.9717, Err 0.7102\n",
      "50: TRAIN Loss 0.4971,  Err 0.2385 || VAL Loss 0.9717, Err 0.7129\n",
      "60: TRAIN Loss 0.4915,  Err 0.2353 || VAL Loss 0.9724, Err 0.7163\n",
      "70: TRAIN Loss 0.4875,  Err 0.2337 || VAL Loss 0.9740, Err 0.7199\n",
      "80: TRAIN Loss 0.4845,  Err 0.2323 || VAL Loss 0.9760, Err 0.7235\n",
      "90: TRAIN Loss 0.4823,  Err 0.2314 || VAL Loss 0.9778, Err 0.7266\n"
     ]
    }
   ],
   "source": [
    "best_F=int(best['F'])\n",
    "best_penalty=best['penalty']\n",
    "\n",
    "best_MFmodel=MatrixFactorCF(N_users,N_movies,best_F,best_penalty)\n",
    "best_MFmodel.compile()\n",
    "best_history=best_MFmodel.fit(users, movies, ratings, users_test, movies_test, ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "wKjQe_wqN7iK",
    "outputId": "b6591fce-a73a-448f-ea9d-a105f5101d46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3507757860>"
      ]
     },
     "execution_count": 365,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the training process\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(best_history.history['rmse'], label='rmse')\n",
    "plt.plot(best_history.history['val_rmse'], label='test_rmse')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title(\"Matrix Factorization Method\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T01:19:05.304297Z",
     "start_time": "2019-09-08T01:19:02.400969Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FtYE7L2wbBRi",
    "outputId": "fca2a04a-f14f-4864-a187-6f10313476dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F=100, penalty=0.0001, test loss=0.7293138903985336\n"
     ]
    }
   ],
   "source": [
    "Y_pred = best_model.predict(users_test,movies_test)\n",
    "test_loss=np.mean((ratings_test-Y_pred)**2)\n",
    "print(f'F={best_F}, penalty={best_penalty}, test loss={test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOq9nmtTc1Ua"
   },
   "source": [
    "## 4. Model Comparison\n",
    "\n",
    "Now we compare the performance of the two collaborative filtering algorithms. Since the item-based model can not measure the mean square errow, we will compare their recommendation lists for performance evaluation, specifically using the precision and recall metrics to examine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJNzJaRezyQ3"
   },
   "source": [
    "### Recommendation for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "UdBjU0S5yUJL",
    "outputId": "7a60dc59-14b9-4646-a35b-1fff679e0f1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>MatrixFactor_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52659</th>\n",
       "      <td>345</td>\n",
       "      <td>779</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.470915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52692</th>\n",
       "      <td>345</td>\n",
       "      <td>3534</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.003760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52668</th>\n",
       "      <td>345</td>\n",
       "      <td>1127</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.085003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52695</th>\n",
       "      <td>345</td>\n",
       "      <td>3801</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.237909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52654</th>\n",
       "      <td>345</td>\n",
       "      <td>11</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.615185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52660</th>\n",
       "      <td>345</td>\n",
       "      <td>838</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.853195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52700</th>\n",
       "      <td>345</td>\n",
       "      <td>5377</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52679</th>\n",
       "      <td>345</td>\n",
       "      <td>2359</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.438814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52707</th>\n",
       "      <td>345</td>\n",
       "      <td>7121</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.947897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52690</th>\n",
       "      <td>345</td>\n",
       "      <td>3396</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.334935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating  MatrixFactor_prediction\n",
       "52659     345      779     5.0                 3.470915\n",
       "52692     345     3534     4.5                 3.003760\n",
       "52668     345     1127     3.5                 3.085003\n",
       "52695     345     3801     4.0                 3.237909\n",
       "52654     345       11     2.5                 3.615185\n",
       "...       ...      ...     ...                      ...\n",
       "52660     345      838     5.0                 2.853195\n",
       "52700     345     5377     3.5                 3.996491\n",
       "52679     345     2359     5.0                 3.438814\n",
       "52707     345     7121     5.0                 2.947897\n",
       "52690     345     3396     3.0                 4.334935\n",
       "\n",
       "[62 rows x 4 columns]"
      ]
     },
     "execution_count": 397,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose a random user\n",
    "idx=np.random.randint(0,len(users_all))\n",
    "test_user=users_all[idx]\n",
    "original_test_user=userEncoder.inverse_transform([test_user])[0]\n",
    "\n",
    "user_ratings = data_ratings[data_ratings['userId'] == original_test_user][['userId', 'movieId', 'rating']]\n",
    "user_ratings['MatrixFactor_prediction'] = best_MFmodel.predict(user_ratings.userId, movieEncoder.fit_transform(user_ratings.movieId))\n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kM0NBGwAycj0",
    "outputId": "e5792983-e79b-4974-d30e-66920d8706ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movies this user rated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                       'Til There Was You (1997)\n",
       "1    Waking Ned Devine (a.k.a. Waking Ned) (1998)\n",
       "2                   Affair to Remember, An (1957)\n",
       "3                            All That Jazz (1979)\n",
       "4                             12 Angry Men (1957)\n",
       "5                                     Emma (1996)\n",
       "6                             'Salem's Lot (2004)\n",
       "7                                    Alien (1979)\n",
       "8                            All About Eve (1950)\n",
       "9                               Adam's Rib (1949)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 399,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 10 movies this user rated\")\n",
    "user_ratings.sort_values(by='rating', ascending=False).merge(data_movies, on='movieId', how='inner', \n",
    "                                                            suffixes=['_u', '_m']).head(10)['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fq4tNVX2y0rh",
    "outputId": "ebcaaae7-14aa-44ef-8456-348358ddfda8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movies recommended for this user\n",
      "ItemBased Recommendation: \n",
      "['For Whom the Bell Tolls (1943)']\n",
      "['Strange Love of Martha Ivers, The (1946)']\n",
      "['Ruthless People (1986)']\n",
      "['Foxfire (1996)']\n",
      "['Some Like It Hot (1959)']\n",
      "['Inspector General, The (1949)']\n",
      "['In the Line of Fire (1993)']\n",
      "\n",
      "Matrix Factorization Recommendation: \n",
      "['Halloween: Resurrection (Halloween 8) (2002)']\n",
      "['Almost Heroes (1998)']\n",
      "['Lilo & Stitch (2002)']\n",
      "['Mr. Saturday Night (1992)']\n",
      "['Monster, The (Mostro, Il) (1994)']\n",
      "['Hocus Pocus (1993)']\n",
      "['Lumumba (2000)']\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 movies recommended for this user\")\n",
    "rec_ItemBased=ItemBasedCFModel.recommend(test_user)\n",
    "rec_MatrixFactor=best_MFmodel.recommend(test_user)\n",
    "\n",
    "rec_ItemBased_title=[data_movies[data_movies.movieId==movie].title for movie in rec_ItemBased]\n",
    "rec_MatrixFactor_title=[data_movies[data_movies.movieId==movie].title for movie in rec_MatrixFactor]\n",
    "\n",
    "print(\"ItemBased Recommendation: \")\n",
    "for movie in rec_ItemBased_title:\n",
    "    if len(movie): print(movie.values)\n",
    "\n",
    "print(\"\\nMatrix Factorization Recommendation: \")\n",
    "for movie in rec_MatrixFactor_title:\n",
    "    if len(movie): print(movie.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vGTuORLoaag"
   },
   "source": [
    "Now we want to compute the precision, recall and F1-score number for these two recommendation algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjaM4NHGogte",
    "outputId": "4e910aad-847e-4404-b09e-94d8bc83e84b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 testing performance now....\n",
      "Iteration 100 testing performance now....\n",
      "Iteration 200 testing performance now....\n",
      "Iteration 300 testing performance now....\n",
      "Iteration 400 testing performance now....\n",
      "Iteration 500 testing performance now....\n",
      "Iteration 600 testing performance now....\n",
      "precision=0.15245901639344261\t recall=0.061483538278460925\n"
     ]
    }
   ],
   "source": [
    "prec1, recall1 = ItemBasedCFModel.test(test_dict)\n",
    "F1_1 = (2*recall1*prec1)/(recall1+prec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TLKUJB394Rbm",
    "outputId": "364c579e-fae8-4962-9866-7cf84747913c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 testing performance now....\n",
      "Iteration 100 testing performance now....\n",
      "Iteration 200 testing performance now....\n",
      "Iteration 300 testing performance now....\n",
      "Iteration 400 testing performance now....\n",
      "Iteration 500 testing performance now....\n",
      "Iteration 600 testing performance now....\n",
      "precision=0.19060955518945634\t recall=0.10636123231521883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prec2, recall2 = best_MFmodel.test_performance(train_dict,test_dict)\n",
    "F1_2 = (2*recall2*prec2)/(recall2+prec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyw6FGN23iRj",
    "outputId": "6c5096b3-d1cb-4a7d-fe3c-c0af732a1c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-based Model: precision=0.15245901639344261, recall=0.061483538278460925, F1-score=0.08762838028832563\n",
      "Matrix Factorization Model: precision=0.19060955518945634, recall=0.10636123231521883, F1-score=0.12852323565438613\n"
     ]
    }
   ],
   "source": [
    "print(f\"Item-based Model: precision={prec1}, recall={recall1}, F1-score={F1_1}\")\n",
    "print(f\"Matrix Factorization Model: precision={prec2}, recall={recall2}, F1-score={F1_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkBQ4LysoRm6"
   },
   "source": [
    "We can see that the precision, recall and F1-score for the Matrix Factorization model is slightly higher than the Item-based model. This is because the MF model considers both the effect of movies and users and their interactions, thus it is more robust especially for predicting the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXHLB3kRe07w"
   },
   "source": [
    "## 5. Future Work\n",
    "\n",
    "Given the limited time (12 hours window), two collaborative filtering algorithms are compared on the MovieLens small dataset (100k). If given more time, we project to finish the following parts to improve this movie recommendation model:\n",
    "\n",
    "1. Consider K-fold cross validation training to improve the model robustness and further avoid the overfitting scenario\n",
    "2. Use larger MovieLens dataset (27M) to train the model and predict:\n",
    "    \n",
    "    This might require use AWS Sagemaker with EC2 instance. Or we can try using Spark with RDD data and mllib library with ALS (Alternating least squares) optimization method to train the matrix factorization models.\n",
    "\n",
    "3. Combine the two algorithms and even other content-based filtering methods to make an ensemble method for better prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgYFd56IbBRl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CollaborativeFiltering_MovieRecommender_Kerry.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
